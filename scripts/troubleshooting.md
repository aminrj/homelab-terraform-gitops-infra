# ðŸ”§ LLM Infrastructure Troubleshooting Guide

## Common Issues and Solutions

### 1. Models Not Loading
**Problem**: Ollama pods are running but models aren't available
**Solution**:
```bash
# Check model download progress
kubectl logs -f deployment/ollama-small-models -n llm-models
kubectl logs -f deployment/ollama-medium-models -n llm-models

# Manually pull models if needed
kubectl exec -it deployment/ollama-small-models -n llm-models -- ollama pull phi3:mini
```

### 2. Gateway Connection Issues
**Problem**: LLM Gateway can't reach Ollama services
**Solution**:
```bash
# Test internal connectivity
kubectl exec -it deployment/llm-gateway-enhanced -n llm-gateway -- curl http://ollama-small-service.llm-models.svc.cluster.local:11434/api/tags

# Check service endpoints
kubectl get endpoints -n llm-models
```

### 3. Slow Response Times
**Problem**: Models taking too long to respond
**Solutions**:
- Use smaller models for testing (phi3:mini, tinyllama)
- Check resource allocation: `kubectl top pods -n llm-models`
- Verify CPU affinity and node selection

### 4. Test Runner Failures
**Problem**: Automated tests failing
**Solution**:
```bash
# Check test runner logs
kubectl logs deployment/llm-test-runner -n llm-testing

# Test connectivity to gateway
kubectl exec -it deployment/llm-test-runner -n llm-testing -- curl http://llm-gateway-enhanced-service.llm-gateway.svc.cluster.local/health
```

### 5. n8n Node Issues
**Problem**: Custom LLM nodes not appearing in n8n
**Solution**:
```bash
# Restart n8n to load new nodes
kubectl rollout restart deployment/n8n -n n8n

# Check if ConfigMap was applied
kubectl get configmap n8n-enhanced-llm -n n8n -o yaml
```

## Performance Optimization

### Model Selection Strategy
- **Quick Testing**: phi3:mini (fastest, 1.8B params)
- **Development**: llama3.2:3b (balanced, good quality)
- **Production**: mistral:7b or llama3 (best quality)

### Resource Allocation
```yaml
# Recommended resource limits
small_models:  cpu: 2-4,  memory: 4-8Gi
medium_models: cpu: 4-6,  memory: 12-16Gi  
large_models:  cpu: 6-10, memory: 24-28Gi
```

### Monitoring Commands
```bash
# Overall system status
kubectl get pods --all-namespaces | grep llm

# Resource usage
kubectl top pods -n llm-models
kubectl top nodes

# Model availability
curl http://llm-test.local/models

# Test performance
curl -X POST http://llm-test.local/chat -H "Content-Type: application/json" -d '{"message":"test","model":"phi3:mini"}'
```
